# -*- coding: utf-8 -*-
"""CBL_Corrected.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nk9e1b7P8Q8kH3MDtnpA01QphAgs0bqK
"""
import pandas as pd

# !pip install torch # Only if not already installed in your environment

import torch.nn as nn
import torch.nn.functional as F
import torch
import numpy as np
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader
import matplotlib.pyplot as plt

# --- 1. DATA LOADING AND INITIAL INSPECTION ---
try:
    loaded_data = np.load("ir_spectra_dataset.npz")
    print(f"Keys in NPZ file: {list(loaded_data.keys())}")
    spectra_data_np = loaded_data['data'] # Shape: (N, L, C_numpy) e.g., (5166, 6048, 2)
    labels_np = loaded_data['labels']     # Shape: (N, num_classes) e.g., (5166, 6)
    print(f"Original data shape: {spectra_data_np.shape}")
    print(f"Original labels shape: {labels_np.shape}")
    if 'label_names' in loaded_data:
        print(f"Label names: {loaded_data['label_names']}")

except FileNotFoundError:
    print("Error: 'ir_spectra_dataset.npz' not found. Make sure the file is in the correct directory.")
    exit()
except Exception as e:
    print(f"Error loading NPZ file: {e}")
    exit()


# --- 2. NORMALIZATION FUNCTION ---
def normalize_per_sample_numpy(sample_np):
    """
    For one sample of shape (L, 2):
     - leave channel 0 (wavenumber) as is
     - normalize channel 1 (intensity) to zero mean and unit std
    """
    # Copy to float32
    out = sample_np.astype(np.float32).copy()

    # Compute mean/std on the intensity channel
    intensity = sample_np[:, 1]
    mu, sigma = intensity.mean(), intensity.std()

    if sigma < 1e-6:
        out[:, 1] = intensity - mu
    else:
        out[:, 1] = (intensity - mu) / sigma

    return out

# def normalize_per_sample_numpy(sample_np):
#     # no normalizationâ€”just cast to float32
#     return sample_np.astype(np.float32)

# def normalize_per_sample_numpy(sample_np):
#     """
#     Normalizes each channel of a single sample (L, C_numpy) to have mean 0 and std 1.
#     Handles cases where a channel might be all zeros (std=0).
#     """
#     normalized_sample = np.zeros_like(sample_np, dtype=np.float32)
#     # sample_np shape is expected to be (length, num_channels_in_numpy_format)
#     # e.g. (6048, 2)
#     for i in range(sample_np.shape[1]): # Iterate over channels
#         channel_data = sample_np[:, i]
#         mean = channel_data.mean()
#         std = channel_data.std()
#         if std < 1e-6: # Avoid division by zero or very small std
#             normalized_sample[:, i] = channel_data - mean # Effectively sets to zero if mean is also zero
#         else:
#             normalized_sample[:, i] = (channel_data - mean) / std
#     return normalized_sample


# Apply to every sample:
X_normalized_np = np.stack([normalize_per_sample_numpy(s)
                            for s in spectra_data_np], axis=0)

print(f"Shape of X_normalized_np: {X_normalized_np.shape}") # Should be (N, L, C_numpy)


# --- 3. DATA PREPARATION FOR PYTORCH ---
# Convert to PyTorch tensors
# X_normalized_np is (N, L, C_in_numpy). PyTorch Conv1D expects (N, C_in_torch, L)
# So, we permute dimensions (0, 2, 1)
X = torch.tensor(X_normalized_np).float().permute(0, 2, 1)
y = torch.tensor(labels_np).float()

print(f"Tensor X shape (N, C_torch, L): {X.shape}, Tensor y shape (N, num_classes): {y.shape}")

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40, shuffle=True)

print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")

# Create DataLoaders
batch_size = 32# Can be tuned

train_dataset = TensorDataset(X_train, y_train)
test_dataset = TensorDataset(X_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)


# --- 4. MODEL DEFINITION (IR1DCNN with BatchNorm and Dropout) ---
class IR1DCNN(nn.Module):
    def __init__(self, input_channels=2, num_classes=6, sequence_length=6048):
        super(IR1DCNN, self).__init__()
        self.conv1 = nn.Conv1d(input_channels, 16, kernel_size=5, padding='same')
        self.bn1 = nn.BatchNorm1d(16)
        self.pool1 = nn.MaxPool1d(2) # L_out = L_in / 2

        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding='same')
        self.bn2 = nn.BatchNorm1d(32)
        self.pool2 = nn.MaxPool1d(2) # L_out = L_in / 2

        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, padding='same')
        self.bn3 = nn.BatchNorm1d(64)
        self.pool3 = nn.MaxPool1d(2)

        self.conv4 = nn.Conv1d(64, 100, kernel_size=5, padding='same')
        self.bn4 = nn.BatchNorm1d(100)
        self.pool4 = nn.MaxPool1d(2)

        self.conv5 = nn.Conv1d(100, 128, kernel_size=5, padding='same')
        self.bn5 = nn.BatchNorm1d(128)
        self.pool5 = nn.MaxPool1d(2)

        self.conv6 = nn.Conv1d(128, 256, kernel_size=5, padding='same')
        self.bn6 = nn.BatchNorm1d(256)
        self.pool6 = nn.MaxPool1d(2)

        # Calculate flattened_size dynamically
        # After conv1 (padding='same'), length = sequence_length
        # After pool1, length = sequence_length / 2
        # After conv2 (padding='same'), length = sequence_length / 2
        # After pool2, length = (sequence_length / 2) / 2 = sequence_length / 4
        current_length = sequence_length
        current_length = current_length // 2 # After pool1
        current_length = current_length // 2 # After pool2
        current_length = current_length // 2 #after pool 3
        current_length = current_length // 2
        current_length = current_length // 2
        current_length = current_length // 2
        self.flattened_size = 256 * current_length # 32 is num_channels from conv2

        self.fc1 = nn.Linear(self.flattened_size, 500)
        self.dropout1 = nn.Dropout(0.5)
        self.fc2 = nn.Linear(500, 250)
        self.dropout2 = nn.Dropout(0.5)
        self.fc3 = nn.Linear(250, 50)
        self.dropout3 = nn.Dropout(0.4)
        # self.fc4 = nn.Linear(50, 100)
        # self.dropout4 = nn.Dropout(0.3)
        # self.fc5 = nn.Linear(250, 100)
        # self.dropout5 = nn.Dropout(0.2)
        # self.fc6 = nn.Linear(100, num_classes)
        # self.dropout6 = nn.Dropout(0.1)
        self.fc4 = nn.Linear(50, num_classes)

    def forward(self, x):
        x = self.pool1(F.relu(self.bn1(self.conv1(x))))
        x = self.pool2(F.relu(self.bn2(self.conv2(x))))
        x = self.pool3(F.relu(self.bn3(self.conv3(x))))
        x = self.pool4(F.relu(self.bn4(self.conv4(x))))
        x = self.pool5(F.relu(self.bn5(self.conv5(x))))
        x = self.pool6(F.relu(self.bn6(self.conv6(x))))
        x = x.view(x.size(0), -1) # Flatten: (batch_size, flattened_features)
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = F.relu(self.fc3(x))
        x = self.dropout3(x)
        # x= F.relu(self.fc4(x))
        # x = self.dropout4(x)
        # x= F.relu(self.fc5(x))
        # x = self.dropout5(x)
        # x = F.relu(self.fc6(x))
        # x = self.dropout6(x)
        return self.fc4(x) # Logits output

# --- 5. SETUP MODEL, LOSS, OPTIMIZER ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Instantiate model with correct sequence length if it's fixed, or pass from data
model = IR1DCNN(input_channels=X.shape[1], num_classes=y.shape[1], sequence_length=X.shape[2]).to(device)
criterion = nn.BCEWithLogitsLoss() # Suitable for multi-label classification
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # Adam is often a good default
#optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.00001)

# Optional: Learning rate scheduler
# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5, verbose=True)

# --- 6. TRAINING LOOP ---
num_epochs = 100 # Start with a moderate number of epochs for testing
best_test_loss = float('inf')
patience = 15 # For early stopping (number of epochs to wait for improvement)
epochs_no_improve = 0

print("Starting training...")
for epoch in range(num_epochs):
    model.train()
    running_train_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs) # These are logits
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_train_loss += loss.item() * inputs.size(0) # Accumulate total loss for the epoch

    epoch_train_loss = running_train_loss / len(train_loader.dataset) # Avg loss per sample

    # Validation step
    model.eval()
    running_test_loss = 0.0
    correct_val_exact_match = 0
    total_val_samples = 0
    threshold = 0.5 # For converting probabilities to binary predictions

    with torch.no_grad():
        for inputs_val, labels_val in test_loader:
            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)
            outputs_val = model(inputs_val) # Logits
            loss_val = criterion(outputs_val, labels_val)
            running_test_loss += loss_val.item() * inputs_val.size(0)

            # For accuracy (exact match)
            preds_val_probs = torch.sigmoid(outputs_val) # Convert logits to probabilities
            preds_val_binary = (preds_val_probs > threshold).bool() # Convert probs to binary 0/1
            correct_val_exact_match += (preds_val_binary == labels_val.bool()).all(dim=1).sum().item()
            total_val_samples += labels_val.size(0)

    epoch_test_loss = running_test_loss / len(test_loader.dataset) # Avg loss per sample
    val_accuracy_exact = 100 * correct_val_exact_match / total_val_samples

    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, Test Accuracy (Exact Match): {val_accuracy_exact:.2f}%")

    # # LR Scheduler step (if using ReduceLROnPlateau)
    # scheduler.step(epoch_test_loss)

    # Early stopping
    if epoch_test_loss < best_test_loss:
        best_test_loss = epoch_test_loss
        epochs_no_improve = 0
        # Optional: Save the best model
        # torch.save(model.state_dict(), 'best_ir_model.pth')
        # print(f"New best model saved with test loss: {best_test_loss:.4f}")
    else:
        epochs_no_improve += 1

    if epochs_no_improve >= patience:
        print(f"Early stopping triggered after {epoch+1} epochs due to no improvement in test loss.")
        break

print('Finished Training')

# --- 7. FINAL EVALUATION (Optional: Load best model if saved) ---
# if os.path.exists('best_ir_model.pth'):
#     print("Loading best model for final evaluation...")
#     model.load_state_dict(torch.load('best_ir_model.pth'))

model.eval()
final_correct_exact_match = 0
final_total_samples = 0
threshold = 0.5

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        preds_probs = torch.sigmoid(outputs)
        preds_binary = (preds_probs > threshold).bool()
        final_correct_exact_match += (preds_binary == labels.bool()).all(dim=1).sum().item()
        final_total_samples += labels.size(0)

final_test_accuracy_exact = 100 * final_correct_exact_match / final_total_samples
print(f"Final Test Accuracy (Exact Match): {final_test_accuracy_exact:.2f}%")

# --- 8. INFERENCE ON FIRST 10 ORIGINAL SAMPLES ---
print("\n--- Inference on first 10 original samples ---")
# Use the original unnormalized numpy data, but normalize each sample before feeding to model
original_spectra_data_np = loaded_data['data'] # Shape (N, L, C_numpy)
original_labels_np = loaded_data['labels']

model.eval()
num_samples_to_show = min(10, len(original_spectra_data_np))
for i in range(num_samples_to_show):
    sample_np_original_format = original_spectra_data_np[i]  # Shape: (L, C_numpy), e.g. (6048, 2)
    true_label_np = original_labels_np[i]                    # Shape: (num_classes), e.g. (6,)

    # Normalize this single sample
    normalized_sample_np = normalize_per_sample_numpy(sample_np_original_format) # Shape (L, C_numpy)

    # Convert to tensor, permute for PyTorch (C_torch, L), and add batch dimension
    sample_tensor = torch.tensor(normalized_sample_np, dtype=torch.float32).permute(1, 0).unsqueeze(0).to(device)  # Shape: (1, C_torch, L)

    with torch.no_grad():
        output_logits = model(sample_tensor)
        prediction_probs = torch.sigmoid(output_logits).cpu().numpy()[0] # Get probabilities for the single sample

    print(f"\nSample {i+1}")
    print(f"True Labels       : {true_label_np.astype(int)}")
    print(f"Predicted (prob.) : {prediction_probs.round(4)}")
    print(f"Predicted (binary): {(prediction_probs > threshold).astype(int)}")

# --- 9. MODEL COMPLEXITY ANALYSIS (MACs, Parameters) ---

try:
    from ptflops import get_model_complexity_info
except ImportError:
    print("ptflops is not installed. Install it via `pip install ptflops` to estimate model complexity.")
else:
    print("\n--- Model Complexity Analysis ---")
    # Use CUDA if available, else default to CPU
    device_idx = 0 if torch.cuda.is_available() else None

    # For 1D input: shape = (C_torch, L)
    input_res = (X.shape[1], X.shape[2])  # (2, 6048)

    with torch.cuda.device(device_idx) if device_idx is not None else torch.cpu.device():
        macs, params = get_model_complexity_info(
            model,
            input_res,
            as_strings=True,
            print_per_layer_stat=True,
            verbose=True
        )
        print(f"\nTotal MACs (Multiply-Accumulate operations): {macs}")
        print(f"Total Parameters: {params}")
# assume model is in eval(), threshold=0.5, device set
all_preds = []
all_trues = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.to(device)
        logits = model(inputs)
        probs = torch.sigmoid(logits).cpu()
        preds = (probs > threshold).int()
        all_preds.append(preds)
        all_trues.append(labels.int())

# concatenate all batches
all_preds = torch.cat(all_preds, dim=0)   # shape (N_test, 6)
all_trues = torch.cat(all_trues, dim=0)   # shape (N_test, 6)

# compute per-class accuracy
per_class_acc = (all_preds == all_trues).sum(dim=0).float() / all_trues.size(0)

# get label names from your dataset
label_names = loaded_data['label_names']  # e.g. ['Alkene', 'Amide', ... ]

for name, acc in zip(label_names, per_class_acc):
    print(f"{name:15s}: {acc*100:5.2f}%")



torch.save(model.state_dict(), "ir_cnn_model.pth")

# --- ADD THIS ENTIRE BLOCK TO THE END OF YOUR TRAINING SCRIPT ---

print("\n--- Plotting a Sample from the Dataset for Comparison ---")

# The data was already normalized and stored in X_normalized_np
# Shape is (num_samples, length, channels) e.g., (5166, 6048, 2)
# Let's choose the first sample from the dataset
sample_to_plot = X_normalized_np[0] # Shape (6048, 2)

# Extract the two channels for plotting
# Channel 0 is standardized wavenumber
# Channel 1 is standardized absorbance
wavenumber_channel = sample_to_plot[:, 0]
absorbance_channel = sample_to_plot[:, 1]

# Create the plot
plt.figure(figsize=(12, 5))
plt.plot(wavenumber_channel, absorbance_channel)

plt.title("Standardized Spectrum from the Training Dataset (Sample 0)")
plt.xlabel("Standardized Wavenumber (Z-score)")
plt.ylabel("Standardized Absorbance (Z-score)")
plt.grid(True, linestyle='--', alpha=0.6)
# IMPORTANT: Set the y-axis limits to be the same as the acetone plot for a fair comparison
plt.ylim(-2, 15) # Match the approximate range of the acetone plot
plt.show()

# You can also print the min and max absorbance to see the range
print(f"Max Z-score for dataset sample 0 absorbance: {absorbance_channel.max():.2f}")
print(f"Min Z-score for dataset sample 0 absorbance: {absorbance_channel.min():.2f}")


